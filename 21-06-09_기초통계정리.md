<img width="785" alt="1" src="https://user-images.githubusercontent.com/72295363/121320834-7accc300-c948-11eb-99cc-0860278d40ba.PNG">
![image-20210609170826396](https://user-images.githubusercontent.com/72295363/121320974-a2239000-c948-11eb-950c-1345ef30def6.png)



## :: 파생변수

* 기존의 변수를 조합하여 새로운 변수를 만들어 내는 것을 의미한다. 예를 들어 어떤 학생의 영어 점수와 수학 점수가 있을 때, 두 점수를 사용하여 평균 점수라는 새로운 변수를 만들 수 있는데, 이 변수를 파생변수라고 한다.



---



## :: EDA

### 1) 정의

수집한 데이터가 들어왔을 때, 이를 다양한 각도에서 관찰하고 이해하는 과정입니다. 한마디로 데이터를 분석하기 전에 그래프나 통계적인 방법으로 자료를 직관적으로 바라보는 과정입니다.

### 2) 필요한 이유

1. 데이터의 분포 및 값을 검토함으로써 데이터가 표현하는 현상을 더 잘 이해하고, 데이터에 대한 잠재적인 문제를 발견할 수 있습니다. 이를 통해, 본격적인 분석에 들어가기에 앞서 데이터의 수집을 결정할 수 있습니다.
2. 다양한 각도에서 살펴보는 과정을 통해 문제 정의 단계에서 미쳐 발생하지 못했을 다양한 패턴을 발견하고, 이를 바탕으로 기존의 가설을 수정하거나 새로운 가설을 세울 수 있습니다.



### 3) 과정

기본적인 출발점은 문제 정의 단계에서 세웠던 연구 질문과 가설을 바탕으로 분석 계획을 세우는 것입니다. 분석 계획에는 어떤 속성 및 속성 간의 관계를 집중적으로 관찰해야 할지, 이를 위한 최적의 방법은 무엇인지가 포함되어야 합니다. 

1. 분석의 목적과 변수가 무엇이 있는지 확인. 개별 변수의 이름이나 설명을 가지는지 확인
2. 데이터를 전체적으로 살펴보기 : 데이터에 문제가 없는지 확인. head나 tail부분을 확인, 추가적으로 다양한 탐색(이상치, 결측치 등을 확인하는 과정)
3. 데이터의 개별 속성값을 관찰 : 각 속성 값이 예측한 범위와 분포를 갖는지 확인. 만약 그렇지 않다면, 이유가 무엇인지를 확인. 
4. 속성 간의 관계에 초점을 맞추어, 개별 속성 관찰에서 찾아내지 못했던 패턴을 발견 (상관관계, 시각화 등)



## 2. 이상값을 찾아내는 부분

데이터에 이상치가 있으면, 이상치가 왜 발생했는지 의미를 파악하는 것이 중요합니다. 그리고 그러한 의미를 파악했으면 어떻게 대처해야 할지(제거, 대체, 유지 등)를 판단해야 합니다. 이상치를 발견하는 기법은 여러 가지가 있고 대표적으로 아래와 같은 방법들이 있습니다. 

 

**1. 개별 데이터 관찰**

데이터값을 눈으로 쭉 훑어보면서 전체적인 추세와 특이사항을 관찰할 수 있습니다. 데이터가 많다고 앞부분만 보면 안 되고, 인덱스에 따른 패턴이 나타날 수도 있으므로 앞, 뒤 or 무작위로 표본을 추출해서 관찰해야 합니다. 단, 이상치들은 작은 크기의 표본에 나타나지 않을 수 있습니다. 

 

**2. 통계 값 활용**

적절한 요약 통계 지표(summary statistics)를 사용할 수 있습니다. 데이터의 중심을 알기 위해서는 평균(mean), 중앙값(median), 최빈값(mode)을 사용할 수 있고 데이터의 분산을 알기 위해 범위(range), 분산(variance)을 사용할 수 있습니다. 통계 지표를 이용할 때는 데이터의 특성에 주의해야 합니다. 예를 들어, 평균에는 집합 내 모든 데이터 값이 반영되기 때문에, 이상치가 있으면 값이 영향을 받지만, 중앙값에는 가운데 위치한 값 하나가 사용되기 때문에 이상치의 존재에도 대표성이 있는 결과를 얻을 수 있습니다. 회사 직원들의 연봉에 대해서 평균을 구하면, 대개 중간값보다 훨씬 높게 나오는데, 그것은 몇몇 고액 연봉자가 평균을 끌어올렸기 때문입니다. 

 

**3. 시각화 활용**

일단은 시각적으로 표현이 되어있는 것을 보면, 분석에 도움이 많이 됩니다. 시각화를 통해 주어진 데이터의 개별 속성에 어떤 통계 지표가 적절한지 결정할 수 있습니다. 시각화 방법에는 확률밀도 함수, 히스토그램, 점 플롯(dotplot), 워드 클라우드, 시계열 차트, 지도 등이 있습니다.

 

**4. 머신러닝 기법 활용**

대표적인 머신러닝 기법으로 K-means를 통해 이상치를 확인 할 수 있습니다. 



---



## :: PCA(주성분 분석) 

- 영상인식, 통계 데이터 분석(주성분 찾기), 데이터 압축(차원감소), 노이즈 제거 등 다양한 활용을 갖는다.

PCA는 데이터 하나 하나에 대한 성분을 분석하는 것이 아니라, 여러 데이터들이 모여 하나의 분포를 이룰 때 이 분포의 주 성분을 분석해 주는 방법이다.

PCA는 2차원 데이터 집합에 대해 PCA를 수행하면 2개의 서로 수직인 주성분 벡터를 반환하고, 3차원 점들에 대해 PCA를 수행하면 3개의 서로 수직인 주성분 벡터들을 반환한다. 예를 들어 3차원 데이터의 경우는 아래 그림과 같이 3개의 서로 수직인 주성분 벡터를 찾아준다.





----



### :: 분류성능평가지표 - Precision(정밀도), Recall(재현율) and Accuracy(정확도)



### 모델의 분류와 정답

모델을 평가하는 요소는 결국, 모델이 내놓은 답과 실제 정답의 관계로써 정의를 내릴 수 있습니다. 정답이 True와 False로 나누어져있고, 분류 모델 또한 True False의 답을 내놓습니다. 그렇게 하면, 아래와 같이 2x2 matrix로 case를 나누어볼 수 있겠네요.



### ![img](https://t1.daumcdn.net/cfile/tistory/99DC064C5BE056CE10)

**<Fig1. Confusion matrix>**

이제 각 case별로 살펴보겠습니다.

- True Positive(TP) : 실제 True인 정답을 True라고 예측 (정답)
- False Positive(FP) : 실제 False인 정답을 True라고 예측 (오답)
- False Negative(FN) : 실제 True인 정답을 False라고 예측 (오답)
- True Negative(TN) : 실제 False인 정답을 False라고 예측 (정답)





### 1. Precision(정밀도) - Positive 정답률, **PPV(Positive Predictive Value)**

**정밀도**란 모델이 True라고 분류한 것 중에서 실제 True인 것의 비율입니다. 즉, 아래와 같은 식으로 표현할 수 있습니다.

### 2. Recall(재현율)

**재현율**이란 실제 True인 것 중에서 모델이 True라고 예측한 것의 비율입니다. 



### 3. Accuracy(정확도)

이제는 또 관점을 다르게 생각해봅시다. 사고의 확장이 빠른 사람들은 예상했겠지만, 위 두 지표는 모두 True를 True라고 옳게 예측한 경우에 대해서만 다루었습니다. 하지만, False를 False라고 예측한 경우도 옳은 경우입니다. 이때, 해당 경우를 고려하는 지표가 바로 **정확도(Accuracy)**입니다. 식으로는 다음과 같이 나타냅니다.

![img](https://t1.daumcdn.net/cfile/tistory/99745F3F5BE0613D1A)

정확도는 가장 직관적으로 모델의 성능을 나타낼 수 있는 평가 지표입니다. 하지만, 여기서 고려해야하는 것이 있습니다. 바로 domain의 편중(bias)입니다. 만약 우리가 예측하고자 하는 한달 동안이 특정 기후에 부합하여 비오는 날이 흔치 않다고 생각해보죠. 이 경우에는 해당 data의 domain이 불균형하게되므로 맑은 것을 예측하는 성능은 높지만, 비가 오는 것을 예측하는 성능은 매우 낮을 수 밖에 없습니다. 따라서 이를 보완할 지표가 필요합니다.

### 4. F1 score

F1 score는 Precision과 Recall의 조화평균입니다. 

![img](https://t1.daumcdn.net/cfile/tistory/993482335BE0641515)

F1 score는 데이터 label이 불균형 구조일 때, 모델의 성능을 정확하게 평가할 수 있으며, 성능을 하나의 숫자로 표현할 수 있습니다. 여기서 단순 산술평균으로 사용하지 않는 이유는 무엇일까요? 우리가 평균 속력을 구할 때, 이 조화평균의 개념을 사용해 본 경험이 있을 것입니다. 조화평균의 본질에 대해 이해해보겠습니다.



---



## :: 공분산 (Covariance, Cov)

* 공분산 (Covariance, Cov)는 2개의 확률변수의 상관 정도를 나타내는 값이다.



![img](https://blog.kakaocdn.net/dn/CPEXZ/btqUUrwXmtM/hcKQIIS9jQj55DOpY1wUqK/img.gif)



### 1. 공분산 행렬

 

항상 컴퓨터 계산을 통해 연산하려면 행렬로써 나타내는게 용이하기 때문에 중요하다.

열벡터값을 가지는 확률변수 X , Y 에 각각의 기댓값을 빼주어 아래의 식처럼 계산하면 공분산을 구할 수 있다.



![img](https://blog.kakaocdn.net/dn/Z52GN/btqU51W5COx/xaoLtb4boBP7kidfcFgK6K/img.png)



------

### 2. 공분산의 문제점

 

공분산은 단순한 상관관계의 방향만을 알려준다.

상관관계의 정도는 알 수 없다.

왜일까?

확률변수의 단위 크기에 영향을 많이 받기 때문이다.

두 확률 변수 X,Y 의 공분산 Cov(X,Y)의 단위는 X와 Y의 곱이다.

그렇다 보니 각 확률 변수의 단위크기가 크면 무조건 공분산의 크기가 크게 나오는 문제가 있다.

 

그래서 극복방법으로 **상관계수(Correlation Coefficient)**를 사용한다.

------

### 3. 상관계수(Correlation Coefficient)

 

상관계수는 확률 변수의 절대적 크기에 영향을 받지 않도록 공분산을 단위화 시킨 것이다.

즉, 공분산에 각 확률변수의 분산을 나누어 줬다고 생각하면 된다.

다시 말하면, 공분산을 정규화 시키면 상관관계를 알 수 있다.



---




## :: 다중공선성 판단 기준 및 해결 방법 :: VIF확인(Multicollinearity)



### 다중공선성 이란?

기본적으로 회귀분석의 전제는 독립변수들로 변수를 선정해야한다. **다중공선성이 있다는 것은 변수들 간의 상관관계가 높다는 것**을 의미한다. 기존 전제가 무너진 것이기 때문에 다중공선성을 없애기 위한 노력이 필요하다.

하지만, 주의할 것이 다중공선성이 있다면 상관관계가 높지만 상관관계가 높다고 다중공선성이 반드시 있지는 않다. 데이터의 수가 적은 경우 변수간 상관관계는 높지만 다중공선성은 없을 수 있다. **다중공선성이 높으면 예측 값의 신뢰구간이 넓게 형성되는 현상**을 가진다.



### 다중공선성 판단 기준 : VIF

<u>다중공선성을 판단하는 지표</u>로 사용하는 것이 VIF이다. <u>**각 변수마다 VIF를 보고 10이상인 경우에 다중공선성이 있다고 판단**</u>할 수 있다.엄격한 경우에 판단 기준을 5로  두는 경우도 있지만 보통 10을 기준으로 한다.



### 다중공선성 해결 방법 : 변수 제거

<u>**다중공선성을 가진 변수는 혼자 존재하지 않는다.**</u> 

```
다중공선성 해결 방법
1. 두 변수 중 하나 제거
2. 제거시 R^2 유지되는 변수를 제거
```

<u>**다중공선성을 해결하기 위해서는 다중공선성을 가지는 변수 중 하나를 제거**</u>해주면 된다.



###### *** 정리**

- 차원축소
- encoding

회귀분석을 수행 -> 다중공선성으로 인한 예측 신뢰구간이 큼 -> VIF 10을 기준삼아 다중공선성을 일으키는 변수 중 하나를 제거함 -> 회귀모델을 개선



##### * 볼츠만의 엔트로피 정의 : S = k logW

